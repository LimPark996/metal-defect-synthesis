{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimPark996/metal-defect-synthesis/blob/main/V0/metal_defect_gradio_demo_LlamaGen_Halton(PoCFinal).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# ğŸ”§ Metal Defect Inpainting - Gradio Demo\n",
        "\n",
        "ê¸ˆì† í‘œë©´ ê²°í•¨ Inpainting ë°ëª¨\n",
        "\n",
        "**ì‚¬ì „ ì¡°ê±´:**\n",
        "- VQGAN Fine-tuning ì™„ë£Œ (`metal_defect_synthesis.ipynb`)\n",
        "- MaskGIT í•™ìŠµ ì™„ë£Œ (`metal_defect_MaskGit.ipynb`)\n",
        "- Google Driveì— ì²´í¬í¬ì¸íŠ¸ ì €ì¥ë¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "## 1. í™˜ê²½ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707b3c5f-c2a2-407e-a820-b49436174bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LlamaGen'...\n",
            "remote: Enumerating objects: 191, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 191 (delta 59), reused 38 (delta 38), pack-reused 97 (from 1)\u001b[K\n",
            "Receiving objects: 100% (191/191), 5.49 MiB | 5.79 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Cloning into 'Halton-MaskGIT'...\n",
            "remote: Enumerating objects: 247, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 247 (delta 51), reused 38 (delta 38), pack-reused 173 (from 1)\u001b[K\n",
            "Receiving objects: 100% (247/247), 14.11 MiB | 15.80 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio omegaconf einops -q\n",
        "\n",
        "# LlamaGen í´ë¡ \n",
        "!git clone https://github.com/FoundationVision/LlamaGen.git\n",
        "\n",
        "# Halton-MaskGIT í´ë¡  (ì„ íƒ: halton sequence í•¨ìˆ˜ë§Œ í•„ìš”í•˜ë©´ ì§ì ‘ ì •ì˜í•´ë„ ë¨)\n",
        "!git clone https://github.com/valeoai/Halton-MaskGIT.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yagRhhoLc0sA",
        "outputId": "4d1dfaaa-7db9-47dc-db8b-0be05483d260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2d973d-58d7-41d1-e0e5-7746ba730c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 12 08:42:54 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   34C    P0             56W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# GPU í™•ì¸\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "path_header"
      },
      "source": [
        "## 2. ê²½ë¡œ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paths"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/LlamaGen')\n",
        "\n",
        "# LlamaGen VQGAN (config í•„ìš” ì—†ìŒ!)\n",
        "VQGAN_CKPT_PATH = \"/content/drive/MyDrive/metal-defect/LlamaGen/checkpoints/vqgan_finetune_up_epoch50.pt\"\n",
        "\n",
        "# Halton MaskGIT\n",
        "MASKGIT_CKPT_PATH = \"/content/drive/MyDrive/metal-defect/halton-maskgit/checkpoints/maskgit_epoch100.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_header"
      },
      "source": [
        "## 3. ì„¤ì • ë° ìƒìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24d9e3b-2521-45e3-fa82-48c5e655f167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ–¥ï¸ Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ì„¤ì • ë° ìƒìˆ˜\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import math\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ğŸ–¥ï¸ Device: {device}\")\n",
        "\n",
        "# ì´ë¯¸ì§€ ì„¤ì •\n",
        "IMAGE_SIZE = 256\n",
        "LATENT_SIZE = 16  # 256 / 16 = 16\n",
        "CODEBOOK_SIZE = 16384\n",
        "CODEBOOK_DIM = 8       # LlamaGenì€ 8ì°¨ì›! (tamingì€ 256)\n",
        "LATENT_SIZE = 16\n",
        "SEQ_LEN = 256\n",
        "NUM_CLASSES = 6\n",
        "MASK_TOKEN_ID = 16384  # vocab_sizeì™€ ë™ì¼\n",
        "\n",
        "# í´ë˜ìŠ¤ ì •ë³´ (NEU-DET + GC10-DET)\n",
        "CLASS_NAMES = ['inclusion', 'pit_hole', 'scratch_crease', 'spot_stain', 'line_crack', 'fold_scale']\n",
        "\n",
        "CLASS_NAMES_KR = [\n",
        "    '0: ê°œì¬ë¬¼ (Inclusion)',\n",
        "    '1: í”¼íŠ¸í™€ (Pit Hole)',\n",
        "    '2: ìŠ¤í¬ë˜ì¹˜/ì£¼ë¦„ (Scratch/Crease)',\n",
        "    '3: ì–¼ë£© (Spot/Stain)',\n",
        "    '4: ê· ì—´ (Line/Crack)',\n",
        "    '5: ì ‘í˜/ìŠ¤ì¼€ì¼ (Fold/Scale)',\n",
        "]\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "\n",
        "# ë§ˆìŠ¤í¬ í”„ë¦¬ì…‹\n",
        "def get_mask_preset(preset_name):\n",
        "    \"\"\"ë§ˆìŠ¤í¬ í”„ë¦¬ì…‹ ë°˜í™˜\"\"\"\n",
        "    presets = {\n",
        "        \"ì¤‘ì•™ (ì‘ìŒ) 6x6\": [],\n",
        "        \"ì¤‘ì•™ (í¼) 8x8\": [],\n",
        "        \"ì¢Œìƒë‹¨ 6x6\": [],\n",
        "        \"ìš°í•˜ë‹¨ 6x6\": []\n",
        "    }\n",
        "\n",
        "    # ì¤‘ì•™ (ì‘ìŒ) 6x6\n",
        "    for y in range(5, 11):\n",
        "        for x in range(5, 11):\n",
        "            presets[\"ì¤‘ì•™ (ì‘ìŒ) 6x6\"].append(y * 16 + x)\n",
        "\n",
        "    # ì¤‘ì•™ (í¼) 8x8\n",
        "    for y in range(4, 12):\n",
        "        for x in range(4, 12):\n",
        "            presets[\"ì¤‘ì•™ (í¼) 8x8\"].append(y * 16 + x)\n",
        "\n",
        "    # ì¢Œìƒë‹¨ 6x6\n",
        "    for y in range(0, 6):\n",
        "        for x in range(0, 6):\n",
        "            presets[\"ì¢Œìƒë‹¨ 6x6\"].append(y * 16 + x)\n",
        "\n",
        "    # ìš°í•˜ë‹¨ 6x6\n",
        "    for y in range(10, 16):\n",
        "        for x in range(10, 16):\n",
        "            presets[\"ìš°í•˜ë‹¨ 6x6\"].append(y * 16 + x)\n",
        "\n",
        "    return presets.get(preset_name, presets[\"ì¤‘ì•™ (ì‘ìŒ) 6x6\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_header"
      },
      "source": [
        "## 4. ëª¨ë¸ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Halton-MaskGIT Transformer êµ¬í˜„\n",
        "# ============================================\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "# ----- ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ -----\n",
        "\n",
        "def modulate(x, shift, scale):\n",
        "    \"\"\"AdaLayerNormì˜ modulation ì—°ì‚°\"\"\"\n",
        "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
        "\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    \"\"\"Root Mean Square Layer Normalization\"\"\"\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "        return self.weight * norm\n",
        "\n",
        "\n",
        "class SwiGLU(nn.Module):\n",
        "    \"\"\"SwiGLU FFN (LLaMA style)\"\"\"\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        # hidden_dim ì¡°ì • (SwiGLUëŠ” 2/3ë°° ì‚¬ìš©)\n",
        "        hidden_dim = int(2 * hidden_dim / 3)\n",
        "        # 256ì˜ ë°°ìˆ˜ë¡œ ë§ì¶¤\n",
        "        hidden_dim = 256 * ((hidden_dim + 255) // 256)\n",
        "\n",
        "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
        "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # SwiGLU: SiLU(W1(x)) * W3(x)\n",
        "        x = F.silu(self.w1(x)) * self.w3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.w2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class QKNorm(nn.Module):\n",
        "    \"\"\"Query/Key Normalization for stable attention\"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.q_norm = RMSNorm(dim)\n",
        "        self.k_norm = RMSNorm(dim)\n",
        "\n",
        "    def forward(self, q, k):\n",
        "        return self.q_norm(q), self.k_norm(k)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"Multi-Head Self-Attention with QK Norm and Flash Attention\"\"\"\n",
        "    def __init__(self, dim, num_heads, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.wq = nn.Linear(dim, dim, bias=False)\n",
        "        self.wk = nn.Linear(dim, dim, bias=False)\n",
        "        self.wv = nn.Linear(dim, dim, bias=False)\n",
        "        self.wo = nn.Linear(dim, dim, bias=False)\n",
        "\n",
        "        self.qk_norm = QKNorm(dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        # Q, K, V projection\n",
        "        q, k, v = self.wq(x), self.wk(x), self.wv(x)\n",
        "\n",
        "        # QK Normalization\n",
        "        q, k = self.qk_norm(q, k)\n",
        "\n",
        "        # Reshape for multi-head\n",
        "        q = q.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Flash Attention (PyTorch 2.0+)\n",
        "        out = F.scaled_dot_product_attention(\n",
        "            q, k, v,\n",
        "            dropout_p=self.dropout.p if self.training else 0.\n",
        "        )\n",
        "\n",
        "        # Reshape back\n",
        "        out = out.transpose(1, 2).contiguous().view(B, N, C)\n",
        "        out = self.wo(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"Transformer Block with AdaLayerNorm\"\"\"\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., dropout=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        # AdaLN modulation MLP\n",
        "        # 6ê°œ íŒŒë¼ë¯¸í„°: gamma1, beta1, alpha1, gamma2, beta2, alpha2\n",
        "        self.adaLN_modulation = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim, dim * 6)\n",
        "        )\n",
        "\n",
        "        # Attention\n",
        "        self.norm1 = RMSNorm(dim)\n",
        "        self.attn = Attention(dim, num_heads, dropout)\n",
        "\n",
        "        # FFN (SwiGLU)\n",
        "        self.norm2 = RMSNorm(dim)\n",
        "        self.ffn = SwiGLU(dim, int(dim * mlp_ratio), dropout)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: [B, N, C] í† í° ì„ë² ë”©\n",
        "            cond: [B, C] í´ë˜ìŠ¤ ì¡°ê±´ ì„ë² ë”©\n",
        "        \"\"\"\n",
        "        # AdaLN modulation íŒŒë¼ë¯¸í„° ê³„ì‚°\n",
        "        gamma1, beta1, alpha1, gamma2, beta2, alpha2 = \\\n",
        "            self.adaLN_modulation(cond).chunk(6, dim=-1)\n",
        "\n",
        "        # Attention with AdaLN\n",
        "        x = x + alpha1.unsqueeze(1) * self.attn(\n",
        "            modulate(self.norm1(x), beta1, gamma1)\n",
        "        )\n",
        "\n",
        "        # FFN with AdaLN\n",
        "        x = x + alpha2.unsqueeze(1) * self.ffn(\n",
        "            modulate(self.norm2(x), beta2, gamma2)\n",
        "        )\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AdaNorm(nn.Module):\n",
        "    \"\"\"Final AdaLayerNorm before output\"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm = RMSNorm(dim)\n",
        "        self.adaLN = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim, dim * 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        shift, scale = self.adaLN(cond).chunk(2, dim=-1)\n",
        "        return modulate(self.norm(x), shift, scale)\n",
        "\n",
        "\n",
        "print(\"âœ… ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì •ì˜ ì™„ë£Œ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIukywWwrZeR",
        "outputId": "1116aa3d-881f-4078-9e2d-b46d33ebe495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maskgit_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a4925d-ea4c-47ed-bc58-1106af64d96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… MaskGITTransformer í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# MaskGIT Transformer ë©”ì¸ í´ë˜ìŠ¤\n",
        "# ============================================\n",
        "\n",
        "class MaskGITTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Halton-MaskGIT ìŠ¤íƒ€ì¼ Bidirectional Transformer\n",
        "\n",
        "    íŠ¹ì§•:\n",
        "    - AdaLayerNormìœ¼ë¡œ í´ë˜ìŠ¤ ì¡°ê±´ ì£¼ì…\n",
        "    - SwiGLU FFN\n",
        "    - QK Normalization\n",
        "    - Weight Tying (tok_emb â†” head)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=16384,      # codebook í¬ê¸°\n",
        "        seq_len=256,           # í† í° ì‹œí€€ìŠ¤ ê¸¸ì´ (16*16)\n",
        "        hidden_dim=512,        # Transformer hidden ì°¨ì›\n",
        "        num_layers=12,         # Transformer ë ˆì´ì–´ ìˆ˜\n",
        "        num_heads=8,           # Multi-head attentionì˜ head ìˆ˜\n",
        "        mlp_ratio=4.,          # FFN hidden ë°°ìœ¨\n",
        "        dropout=0.1,           # Dropout ë¹„ìœ¨\n",
        "        num_classes=6,         # í´ë˜ìŠ¤ ìˆ˜\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.mask_token_id = vocab_size  # [MASK] = 16384\n",
        "\n",
        "        # ===== Embeddings =====\n",
        "        # í† í° ì„ë² ë”©: 0~16383 (codebook) + 16384 ([MASK])\n",
        "        self.tok_emb = nn.Embedding(vocab_size + 1, hidden_dim)\n",
        "\n",
        "        # ìœ„ì¹˜ ì„ë² ë”©: 0~255 (16x16 ìœ„ì¹˜)\n",
        "        self.pos_emb = nn.Embedding(seq_len, hidden_dim)\n",
        "\n",
        "        # í´ë˜ìŠ¤ ì„ë² ë”©: 0~5 (ê²°í•¨ í´ë˜ìŠ¤) + 6 (CFGìš© null class)\n",
        "        self.cls_emb = nn.Embedding(num_classes + 1, hidden_dim)\n",
        "\n",
        "        # ===== Transformer Blocks =====\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(hidden_dim, num_heads, mlp_ratio, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # ===== Output =====\n",
        "        self.final_norm = AdaNorm(hidden_dim)\n",
        "\n",
        "        # ì¶œë ¥ í—¤ë“œ (Weight Tying)\n",
        "        self.head = nn.Linear(hidden_dim, vocab_size + 1, bias=False)\n",
        "        self.head.weight = self.tok_emb.weight  # â­ Weight Tying!\n",
        "\n",
        "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\"\"\"\n",
        "        # ì„ë² ë”© ì´ˆê¸°í™”\n",
        "        nn.init.normal_(self.tok_emb.weight, std=0.02)\n",
        "        nn.init.normal_(self.pos_emb.weight, std=0.02)\n",
        "        nn.init.normal_(self.cls_emb.weight, std=0.02)\n",
        "\n",
        "        # AdaLN modulation ë ˆì´ì–´ zero ì´ˆê¸°í™”\n",
        "        for block in self.blocks:\n",
        "            nn.init.zeros_(block.adaLN_modulation[1].weight)\n",
        "            nn.init.zeros_(block.adaLN_modulation[1].bias)\n",
        "\n",
        "    def forward(self, x, y, drop_label=None):\n",
        "        \"\"\"\n",
        "        ìˆœì „íŒŒ\n",
        "\n",
        "        Args:\n",
        "            x: [B, H, W] ë˜ëŠ” [B, N] - ë§ˆìŠ¤í‚¹ëœ í† í° (ì¼ë¶€ê°€ 16384)\n",
        "            y: [B] - í´ë˜ìŠ¤ ë¼ë²¨ (0~5)\n",
        "            drop_label: [B] bool - Trueë©´ í•´ë‹¹ ìƒ˜í”Œì˜ í´ë˜ìŠ¤ ì¡°ê±´ ë¬´ì‹œ (CFGìš©)\n",
        "\n",
        "        Returns:\n",
        "            logits: [B, N, vocab_size+1] - ê° ìœ„ì¹˜ì˜ ì˜ˆì¸¡ í™•ë¥ \n",
        "        \"\"\"\n",
        "        B = x.shape[0]\n",
        "\n",
        "        # [B, H, W] â†’ [B, N] ë³€í™˜\n",
        "        if x.dim() == 3:\n",
        "            x = x.view(B, -1)\n",
        "\n",
        "        # ===== í´ë˜ìŠ¤ ì¡°ê±´ ì²˜ë¦¬ =====\n",
        "        if drop_label is not None:\n",
        "            # drop_labelì´ Trueì¸ ìƒ˜í”Œì€ null class (num_classes)ë¡œ ëŒ€ì²´\n",
        "            y = torch.where(drop_label, torch.full_like(y, self.num_classes), y)\n",
        "\n",
        "        # í´ë˜ìŠ¤ ì„ë² ë”©: [B] â†’ [B, hidden_dim]\n",
        "        cond = self.cls_emb(y)\n",
        "\n",
        "        # ===== í† í° + ìœ„ì¹˜ ì„ë² ë”© =====\n",
        "        # ìœ„ì¹˜ ì¸ë±ìŠ¤ ìƒì„±\n",
        "        pos = torch.arange(self.seq_len, device=x.device)\n",
        "\n",
        "        # ì„ë² ë”©: [B, N] â†’ [B, N, hidden_dim]\n",
        "        x = self.tok_emb(x) + self.pos_emb(pos)\n",
        "\n",
        "        # ===== Transformer ë¸”ë¡ í†µê³¼ =====\n",
        "        for block in self.blocks:\n",
        "            x = block(x, cond)\n",
        "\n",
        "        # ===== ì¶œë ¥ =====\n",
        "        x = self.final_norm(x, cond)\n",
        "        logits = self.head(x)  # [B, N, vocab_size+1]\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "print(\"âœ… MaskGITTransformer í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_header"
      },
      "source": [
        "## 5. ëª¨ë¸ ë¡œë”©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_vqgan"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VQGAN ë¡œë”©\n",
        "# =============================================================================\n",
        "\n",
        "from tokenizer.tokenizer_image.vq_model import VQ_models\n",
        "\n",
        "# LlamaGen VQ-16 ë¡œë“œ\n",
        "vqgan = VQ_models[\"VQ-16\"](\n",
        "    codebook_size=CODEBOOK_SIZE,     # 16384\n",
        "    codebook_embed_dim=CODEBOOK_DIM  # 8\n",
        ")\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
        "checkpoint = torch.load(VQGAN_CKPT_PATH, map_location=device)\n",
        "if \"vqmodel\" in checkpoint:\n",
        "    state_dict = checkpoint[\"vqmodel\"]\n",
        "else:\n",
        "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
        "\n",
        "vqgan.load_state_dict(state_dict, strict=True)\n",
        "vqgan = vqgan.to(device)\n",
        "vqgan.eval()\n",
        "for param in vqgan.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ”„ MaskGIT ë¡œë”© ì¤‘...\")\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
        "ckpt = torch.load(MASKGIT_CKPT_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "# config í™•ì¸\n",
        "if 'config' in ckpt:\n",
        "    model_config = ckpt['config'].copy()  # ì›ë³¸ ìˆ˜ì • ë°©ì§€\n",
        "\n",
        "    # MaskGITTransformerê°€ ë°›ì§€ ì•ŠëŠ” í‚¤ ì œê±°\n",
        "    keys_to_remove = ['model_size']\n",
        "    for key in keys_to_remove:\n",
        "        model_config.pop(key, None)  # ìˆìœ¼ë©´ ì œê±°, ì—†ìœ¼ë©´ ë¬´ì‹œ\n",
        "\n",
        "    print(f\"ğŸ“‹ ì‚¬ìš©í•  config: {model_config}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko3gDJ8Yv2x_",
        "outputId": "df62add8-81fa-495c-88f7-644cf2b8b05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”„ MaskGIT ë¡œë”© ì¤‘...\n",
            "ğŸ“‹ ì‚¬ìš©í•  config: {'vocab_size': 16384, 'seq_len': 256, 'num_classes': 6, 'hidden_dim': 512, 'num_layers': 12, 'num_heads': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_maskgit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5394f683-fcf1-45cb-ad1f-839f7cc2be7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”„ MaskGIT ë¡œë”© ì¤‘...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskGITTransformer(\n",
              "  (tok_emb): Embedding(16385, 512)\n",
              "  (pos_emb): Embedding(256, 512)\n",
              "  (cls_emb): Embedding(7, 512)\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x TransformerBlock(\n",
              "      (adaLN_modulation): Sequential(\n",
              "        (0): SiLU()\n",
              "        (1): Linear(in_features=512, out_features=3072, bias=True)\n",
              "      )\n",
              "      (norm1): RMSNorm()\n",
              "      (attn): Attention(\n",
              "        (wq): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (wk): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (wv): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (wo): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (qk_norm): QKNorm(\n",
              "          (q_norm): RMSNorm()\n",
              "          (k_norm): RMSNorm()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm2): RMSNorm()\n",
              "      (ffn): SwiGLU(\n",
              "        (w1): Linear(in_features=512, out_features=1536, bias=False)\n",
              "        (w2): Linear(in_features=1536, out_features=512, bias=False)\n",
              "        (w3): Linear(in_features=512, out_features=1536, bias=False)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (final_norm): AdaNorm(\n",
              "    (norm): RMSNorm()\n",
              "    (adaLN): Sequential(\n",
              "      (0): SiLU()\n",
              "      (1): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (head): Linear(in_features=512, out_features=16385, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# MaskGIT ë¡œë”©\n",
        "# =============================================================================\n",
        "\n",
        "print(\"ğŸ”„ MaskGIT ë¡œë”© ì¤‘...\")\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
        "ckpt = torch.load(MASKGIT_CKPT_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "# Halton MaskGIT ëª¨ë¸ ìƒì„± (configê°€ ì €ì¥ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©)\n",
        "maskgit = MaskGITTransformer(**model_config).to(device)\n",
        "maskgit.load_state_dict(ckpt['model_state_dict'])\n",
        "maskgit.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "functions_header"
      },
      "source": [
        "## 6. í•µì‹¬ í•¨ìˆ˜ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "encode_decode"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def encode_to_tokens(images, vqgan_model):\n",
        "    \"\"\"LlamaGen ë°©ì‹ ì¸ì½”ë”©\"\"\"\n",
        "    _, _, (_, _, indices) = vqgan_model.encode(images)\n",
        "    batch_size = images.shape[0]\n",
        "    tokens = indices.view(batch_size, LATENT_SIZE, LATENT_SIZE)\n",
        "    return tokens\n",
        "\n",
        "@torch.no_grad()\n",
        "def decode_from_tokens(tokens, vqgan_model):\n",
        "    \"\"\"LlamaGen ë°©ì‹ ë””ì½”ë”©\"\"\"\n",
        "    batch_size = tokens.shape[0]\n",
        "    tokens_flat = tokens.view(-1)\n",
        "    tokens_flat = torch.clamp(tokens_flat, 0, CODEBOOK_SIZE - 1)\n",
        "    embed_dim = vqgan_model.quantize.embedding.weight.shape[1]  # 8\n",
        "\n",
        "    images = vqgan_model.decode_code(\n",
        "        tokens_flat,\n",
        "        shape=(batch_size, embed_dim, LATENT_SIZE, LATENT_SIZE)\n",
        "    )\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inpaint_functions"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Cosine Schedule ë° Inpainting í•¨ìˆ˜\n",
        "# =============================================================================\n",
        "\n",
        "def cosine_schedule(t):\n",
        "    \"\"\"Cosine masking schedule\"\"\"\n",
        "    return torch.cos(t * torch.pi / 2)\n",
        "\n",
        "@torch.no_grad()\n",
        "def inpaint_image(\n",
        "    original_image,\n",
        "    mask_region,\n",
        "    target_class,\n",
        "    maskgit_model,\n",
        "    vqgan_model,\n",
        "    num_steps=8,\n",
        "    temperature=1.0,\n",
        "    device='cuda'\n",
        "):\n",
        "    \"\"\"\n",
        "    ì›ë³¸ ì´ë¯¸ì§€ì˜ ì¼ë¶€ ì˜ì—­ì„ íŠ¹ì • ê²°í•¨ìœ¼ë¡œ ì±„ì›€ (Inpainting)\n",
        "\n",
        "    Args:\n",
        "        original_image: [1, 3, 256, 256] ì›ë³¸ ì´ë¯¸ì§€ (ê°’ ë²”ìœ„ [-1, 1])\n",
        "        mask_region: ë§ˆìŠ¤í‚¹í•  ì˜ì—­ì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (0~255)\n",
        "        target_class: ì–´ë–¤ ê²°í•¨ìœ¼ë¡œ ì±„ìš¸ì§€ (0~5)\n",
        "        num_steps: ë””ì½”ë”© ìŠ¤í… ìˆ˜\n",
        "        temperature: ìƒ˜í”Œë§ ì˜¨ë„\n",
        "\n",
        "    Returns:\n",
        "        result_image: Inpainting ê²°ê³¼ ì´ë¯¸ì§€\n",
        "    \"\"\"\n",
        "    maskgit_model.eval()\n",
        "\n",
        "    # ì…ë ¥ í˜•íƒœ ë§ì¶”ê¸°\n",
        "    if original_image.dim() == 3:\n",
        "        original_image = original_image.unsqueeze(0)\n",
        "    original_image = original_image.to(device)\n",
        "\n",
        "    mask_token_id = maskgit_model.mask_token_id\n",
        "    seq_len = maskgit_model.seq_len\n",
        "\n",
        "    # mask_regionì„ í…ì„œë¡œ ë³€í™˜\n",
        "    if isinstance(mask_region, list):\n",
        "        mask_region = torch.tensor(mask_region, device=device)\n",
        "\n",
        "    num_mask_tokens = len(mask_region)\n",
        "\n",
        "    # 1. ì›ë³¸ ì´ë¯¸ì§€ â†’ í† í°\n",
        "    original_tokens = encode_to_tokens(original_image, vqgan_model)\n",
        "\n",
        "    # 2. ë§ˆìŠ¤í‚¹í•  ì˜ì—­ë§Œ [MASK]ë¡œ êµì²´\n",
        "    tokens = original_tokens.clone().view(1, -1)\n",
        "    tokens[:, mask_region] = mask_token_id\n",
        "\n",
        "    # 3. í´ë˜ìŠ¤ ë¼ë²¨\n",
        "    labels = torch.tensor([target_class], device=device)\n",
        "\n",
        "    drop_label = torch.zeros(1, dtype=torch.bool, device=device)\n",
        "\n",
        "    # 4. Iterative decoding (cosine schedule)\n",
        "    for step in range(num_steps):\n",
        "        is_masked = (tokens == mask_token_id)\n",
        "        num_masked = is_masked.sum().item()\n",
        "\n",
        "        if num_masked == 0:\n",
        "            break\n",
        "\n",
        "        # Cosine scheduleë¡œ ì´ë²ˆ ìŠ¤í…ì—ì„œ í™•ì •í•  ê°œìˆ˜ ê³„ì‚°\n",
        "        t = torch.tensor(step / num_steps, device=device)\n",
        "        ratio = cosine_schedule(t)\n",
        "        num_to_keep_masked = (ratio * num_mask_tokens).long().item()\n",
        "        num_to_unmask = max(1, num_masked - num_to_keep_masked)\n",
        "\n",
        "        # ì˜ˆì¸¡\n",
        "        logits = maskgit_model(tokens, labels, drop_label)\n",
        "        logits = logits / temperature\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        max_probs, predicted_tokens = probs.max(dim=-1)\n",
        "\n",
        "        # ë§ˆìŠ¤í‚¹ëœ ìœ„ì¹˜ë§Œ ê³ ë ¤\n",
        "        max_probs = max_probs * is_masked.float()\n",
        "\n",
        "        # ìƒìœ„ kê°œ ì„ íƒí•´ì„œ í™•ì •\n",
        "        _, top_k = max_probs.view(-1).topk(num_to_unmask)\n",
        "        tokens.view(-1)[top_k] = predicted_tokens.view(-1)[top_k]\n",
        "\n",
        "    # ë‚¨ì€ [MASK] ê°•ì œë¡œ ì±„ìš°ê¸°\n",
        "    is_masked = (tokens == mask_token_id)\n",
        "    if is_masked.any():\n",
        "        logits = maskgit_model(tokens, labels, drop_label)\n",
        "        probs = F.softmax(logits / temperature, dim=-1)\n",
        "        _, predicted_tokens = probs.max(dim=-1)\n",
        "        tokens[is_masked] = predicted_tokens[is_masked]\n",
        "\n",
        "    # 5. í† í° â†’ ì´ë¯¸ì§€\n",
        "    tokens = tokens.view(1, LATENT_SIZE, LATENT_SIZE)\n",
        "    result_image = decode_from_tokens(tokens, vqgan_model)\n",
        "\n",
        "    return result_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Halton Sequence ìƒì„±\n",
        "# ============================================\n",
        "\n",
        "def halton_sequence(base, n_samples):\n",
        "    \"\"\"\n",
        "    Halton sequence ìƒì„± (1D)\n",
        "\n",
        "    Args:\n",
        "        base: ê¸°ì € (ì†Œìˆ˜ ì‚¬ìš©: 2, 3, 5, ...)\n",
        "        n_samples: ìƒì„±í•  ìƒ˜í”Œ ìˆ˜\n",
        "\n",
        "    Returns:\n",
        "        list of floats in [0, 1)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for i in range(1, n_samples + 1):\n",
        "        f = 1.0\n",
        "        r = 0.0\n",
        "        n = i\n",
        "        while n > 0:\n",
        "            f /= base\n",
        "            r += f * (n % base)\n",
        "            n //= base\n",
        "        result.append(r)\n",
        "    return result\n",
        "\n",
        "\n",
        "def build_halton_mask(input_size, n_points=10000):\n",
        "    \"\"\"\n",
        "    2D Halton mask ìƒì„±\n",
        "\n",
        "    Args:\n",
        "        input_size: 16 (16x16 = 256 í† í°)\n",
        "        n_points: ì¶©ë¶„íˆ í° ìˆ˜ (ì¤‘ë³µ ì œê±° í›„ 256ê°œ ë‚¨ìŒ)\n",
        "\n",
        "    Returns:\n",
        "        mask: [256, 2] í…ì„œ, ê° í–‰ì€ (row, col) ì¢Œí‘œ\n",
        "    \"\"\"\n",
        "    # 2D Halton sequence (base 2, 3)\n",
        "    x = halton_sequence(2, n_points)\n",
        "    y = halton_sequence(3, n_points)\n",
        "\n",
        "    # [0, 1) â†’ [0, input_size) ìŠ¤ì¼€ì¼ë§\n",
        "    coords = []\n",
        "    seen = set()\n",
        "\n",
        "    for xi, yi in zip(x, y):\n",
        "        row = int(xi * input_size)\n",
        "        col = int(yi * input_size)\n",
        "\n",
        "        # ë²”ìœ„ ì²´í¬\n",
        "        row = min(row, input_size - 1)\n",
        "        col = min(col, input_size - 1)\n",
        "\n",
        "        # ì¤‘ë³µ ì œê±°\n",
        "        if (row, col) not in seen:\n",
        "            seen.add((row, col))\n",
        "            coords.append([row, col])\n",
        "\n",
        "        # 256ê°œ ëª¨ì´ë©´ ì¢…ë£Œ\n",
        "        if len(coords) >= input_size ** 2:\n",
        "            break\n",
        "\n",
        "    return torch.tensor(coords, dtype=torch.long)\n",
        "\n",
        "\n",
        "# Halton mask ìƒì„± (í•œ ë²ˆë§Œ)\n",
        "HALTON_MASK = build_halton_mask(LATENT_SIZE)\n",
        "print(f\"âœ… Halton mask ìƒì„±: {HALTON_MASK.shape}\")  # [256, 2]\n",
        "print(f\"   ì²˜ìŒ 5ê°œ ì¢Œí‘œ: {HALTON_MASK[:5].tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyKJWu8JqH0R",
        "outputId": "4d59dd2e-05d4-4c25-ae5b-78d845d4fc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Halton mask ìƒì„±: torch.Size([256, 2])\n",
            "   ì²˜ìŒ 5ê°œ ì¢Œí‘œ: [[8, 5], [4, 10], [12, 1], [2, 7], [10, 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Halton Sampler í´ë˜ìŠ¤\n",
        "# ============================================\n",
        "\n",
        "class HaltonSampler:\n",
        "    \"\"\"\n",
        "    Halton-MaskGIT ìŠ¤íƒ€ì¼ ìƒ˜í”ŒëŸ¬\n",
        "\n",
        "    íŠ¹ì§•:\n",
        "    - Halton sequenceë¡œ í† í° ìˆœì„œ ê²°ì • (ê³µê°„ì  ê· ì¼ì„±)\n",
        "    - CFG (Classifier-Free Guidance) ì§€ì›\n",
        "    - Temperature scheduling\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_steps=32,          # ìƒì„± ìŠ¤í… ìˆ˜\n",
        "        cfg_weight=2.0,        # CFG ê°€ì¤‘ì¹˜\n",
        "        temperature=1.0,       # Softmax ì˜¨ë„\n",
        "        randomize=True,        # Halton ì‹œí€€ìŠ¤ ëœë¤í™”\n",
        "    ):\n",
        "        self.num_steps = num_steps\n",
        "        self.cfg_weight = cfg_weight\n",
        "        self.temperature = temperature\n",
        "        self.randomize = randomize\n",
        "        self.halton_mask = HALTON_MASK\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, model, vqgan, num_samples, class_labels, device):\n",
        "        \"\"\"\n",
        "        ì´ë¯¸ì§€ ìƒì„±\n",
        "\n",
        "        Args:\n",
        "            model: MaskGITTransformer\n",
        "            vqgan: VQGAN ë””ì½”ë”\n",
        "            num_samples: ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜\n",
        "            class_labels: [num_samples] í´ë˜ìŠ¤ ë¼ë²¨\n",
        "            device: cuda/cpu\n",
        "\n",
        "        Returns:\n",
        "            images: [num_samples, 3, 256, 256] ìƒì„±ëœ ì´ë¯¸ì§€\n",
        "            codes: [num_samples, 16, 16] ìƒì„±ëœ í† í°\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        B = num_samples\n",
        "        H = W = LATENT_SIZE\n",
        "        seq_len = H * W\n",
        "\n",
        "        # 1. ì „ì²´ [MASK]ë¡œ ì´ˆê¸°í™”\n",
        "        code = torch.full((B, H, W), MASK_TOKEN_ID, device=device)\n",
        "\n",
        "        # 2. í´ë˜ìŠ¤ ë¼ë²¨ ì¤€ë¹„\n",
        "        labels = class_labels.to(device)\n",
        "\n",
        "        # 3. CFGìš© ë¼ë²¨ (unconditional)\n",
        "        drop_label_cond = torch.zeros(B, dtype=torch.bool, device=device)  # ì¡°ê±´ë¶€\n",
        "        drop_label_uncond = torch.ones(B, dtype=torch.bool, device=device)  # ë¬´ì¡°ê±´ë¶€\n",
        "\n",
        "        # 4. Halton mask ì¤€ë¹„ (ìƒ˜í”Œë§ˆë‹¤ ëœë¤ ì˜¤í”„ì…‹)\n",
        "        if self.randomize:\n",
        "            offsets = torch.randint(0, seq_len, (B,))\n",
        "            halton_masks = torch.stack([\n",
        "                torch.roll(self.halton_mask, shifts=offset.item(), dims=0)\n",
        "                for offset in offsets\n",
        "            ])  # [B, 256, 2]\n",
        "        else:\n",
        "            halton_masks = self.halton_mask.unsqueeze(0).expand(B, -1, -1)\n",
        "\n",
        "        halton_masks = halton_masks.to(device)\n",
        "\n",
        "        # 5. ìŠ¤í…ë³„ ìƒì„±\n",
        "        prev_idx = 0\n",
        "\n",
        "        for step in tqdm(range(self.num_steps), desc=\"Sampling\", leave=False):\n",
        "            # ì´ë²ˆ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡í•  í† í° ìˆ˜ (arccos schedule)\n",
        "            ratio = (step + 1) / self.num_steps\n",
        "            r = 1 - (math.acos(ratio) / (math.pi * 0.5))\n",
        "            curr_idx = max(step + 1, int(r * seq_len))\n",
        "            curr_idx = min(curr_idx, seq_len)\n",
        "\n",
        "            # ì´ë²ˆ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡í•  ìœ„ì¹˜ë“¤\n",
        "            positions = halton_masks[:, prev_idx:curr_idx]  # [B, num_new, 2]\n",
        "\n",
        "            if positions.shape[1] == 0:\n",
        "                continue\n",
        "\n",
        "            # Forward (CFG)\n",
        "            if self.cfg_weight > 0:\n",
        "                # ì¡°ê±´ë¶€ + ë¬´ì¡°ê±´ë¶€ ë™ì‹œ ê³„ì‚°\n",
        "                code_double = torch.cat([code, code], dim=0)\n",
        "                labels_double = torch.cat([labels, labels], dim=0)\n",
        "                drop_double = torch.cat([drop_label_cond, drop_label_uncond], dim=0)\n",
        "\n",
        "                logits_double = model(code_double, labels_double, drop_double)\n",
        "                logits_cond, logits_uncond = logits_double.chunk(2, dim=0)\n",
        "\n",
        "                # CFG ê³µì‹\n",
        "                logits = (1 + self.cfg_weight) * logits_cond - self.cfg_weight * logits_uncond\n",
        "            else:\n",
        "                logits = model(code, labels, drop_label_cond)\n",
        "\n",
        "            # Softmax + ìƒ˜í”Œë§\n",
        "            logits = logits.view(B, H, W, -1)  # [B, H, W, vocab+1]\n",
        "            probs = F.softmax(logits / self.temperature, dim=-1)\n",
        "\n",
        "            # ê° ìœ„ì¹˜ì—ì„œ í† í° ìƒ˜í”Œë§\n",
        "            for b in range(B):\n",
        "                for pos in positions[b]:\n",
        "                    row, col = pos[0].item(), pos[1].item()\n",
        "                    prob = probs[b, row, col, :CODEBOOK_SIZE]  # [MASK] ì œì™¸\n",
        "                    prob = prob / prob.sum()  # ì¬ì •ê·œí™”\n",
        "\n",
        "                    # Categorical ìƒ˜í”Œë§\n",
        "                    sampled_token = torch.multinomial(prob, 1).item()\n",
        "                    code[b, row, col] = sampled_token\n",
        "\n",
        "            prev_idx = curr_idx\n",
        "\n",
        "        # 6. VQGAN ë””ì½”ë”©\n",
        "        code = torch.clamp(code, 0, CODEBOOK_SIZE - 1)\n",
        "        images = decode_from_tokens(code, vqgan)\n",
        "        images = torch.clamp(images, -1, 1)\n",
        "\n",
        "        model.train()\n",
        "        return images, code\n",
        "\n",
        "\n",
        "# Sampler ìƒì„±\n",
        "sampler = HaltonSampler(\n",
        "    num_steps=32,\n",
        "    cfg_weight=2.0,\n",
        "    temperature=1.0,\n",
        "    randomize=True\n",
        ")\n",
        "\n",
        "print(\"âœ… Halton Sampler ìƒì„± ì™„ë£Œ\")\n",
        "print(f\"   Steps: {sampler.num_steps}\")\n",
        "print(f\"   CFG Weight: {sampler.cfg_weight}\")\n",
        "print(f\"   Temperature: {sampler.temperature}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfp0qTd9qK5a",
        "outputId": "3effc610-fcec-45a7-ddd6-d660ccbd1207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Halton Sampler ìƒì„± ì™„ë£Œ\n",
            "   Steps: 32\n",
            "   CFG Weight: 2.0\n",
            "   Temperature: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
        "# =============================================================================\n",
        "\n",
        "def preprocess_image(pil_image):\n",
        "    \"\"\"PIL Image â†’ ëª¨ë¸ ì…ë ¥ í…ì„œ\"\"\"\n",
        "    transform = T.Compose([\n",
        "        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        T.Grayscale(num_output_channels=3),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    if pil_image.mode != 'RGB':\n",
        "        pil_image = pil_image.convert('RGB')\n",
        "\n",
        "    tensor = transform(pil_image).unsqueeze(0)  # [1, 3, 256, 256]\n",
        "    return tensor.to(device)\n",
        "\n",
        "\n",
        "def tensor_to_pil(tensor):\n",
        "    \"\"\"í…ì„œ â†’ PIL Image\"\"\"\n",
        "    tensor = tensor.cpu().detach()\n",
        "\n",
        "    if tensor.dim() == 4:\n",
        "        tensor = tensor[0]\n",
        "\n",
        "    # [-1, 1] â†’ [0, 1]\n",
        "    tensor = (tensor + 1) / 2\n",
        "    tensor = tensor.clamp(0, 1)\n",
        "\n",
        "    # [C, H, W] â†’ [H, W, C]\n",
        "    numpy_img = tensor.permute(1, 2, 0).numpy()\n",
        "    numpy_img = (numpy_img * 255).astype(np.uint8)\n",
        "\n",
        "    return Image.fromarray(numpy_img)\n",
        "\n",
        "\n",
        "def visualize_mask_on_image(pil_image, mask_indices, color=(255, 0, 0), alpha=0.4):\n",
        "    \"\"\"ì´ë¯¸ì§€ ìœ„ì— ë§ˆìŠ¤í¬ ì˜ì—­ ì‹œê°í™”\"\"\"\n",
        "    img_np = np.array(pil_image.resize((IMAGE_SIZE, IMAGE_SIZE))).astype(np.float32)\n",
        "\n",
        "    # ë§ˆìŠ¤í¬ ìƒì„±\n",
        "    mask = np.zeros((LATENT_SIZE, LATENT_SIZE), dtype=np.float32)\n",
        "    for idx in mask_indices:\n",
        "        y = idx // LATENT_SIZE\n",
        "        x = idx % LATENT_SIZE\n",
        "        mask[y, x] = 1.0\n",
        "\n",
        "    # ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì—…ìŠ¤ì¼€ì¼\n",
        "    scale = IMAGE_SIZE // LATENT_SIZE\n",
        "    mask_upscaled = np.kron(mask, np.ones((scale, scale)))\n",
        "    mask_3d = np.stack([mask_upscaled] * 3, axis=-1)\n",
        "\n",
        "    # ì˜¤ë²„ë ˆì´\n",
        "    color_overlay = np.array(color, dtype=np.float32).reshape(1, 1, 3)\n",
        "    overlay = img_np * (1 - mask_3d * alpha) + color_overlay * mask_3d * alpha\n",
        "    overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return Image.fromarray(overlay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gradio_header"
      },
      "source": [
        "## 7. Gradio ì•± ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gradio_functions"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Gradio ì•±\n",
        "# =============================================================================\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Inpainting í•¨ìˆ˜ (Gradioìš©)\n",
        "def gradio_inpaint(image, defect_type, mask_preset, num_steps, temperature):\n",
        "    \"\"\"\n",
        "    Gradioì—ì„œ í˜¸ì¶œí•˜ëŠ” Inpainting í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return None, None, None, \"âŒ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!\"\n",
        "\n",
        "    try:\n",
        "        # PIL Imageë¡œ ë³€í™˜\n",
        "        if isinstance(image, np.ndarray):\n",
        "            pil_image = Image.fromarray(image)\n",
        "        else:\n",
        "            pil_image = image\n",
        "\n",
        "        # í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
        "        class_idx = CLASS_NAMES_KR.index(defect_type)\n",
        "\n",
        "        # ë§ˆìŠ¤í¬ ì¸ë±ìŠ¤\n",
        "        mask_indices = get_mask_preset(mask_preset)\n",
        "\n",
        "        # ì „ì²˜ë¦¬\n",
        "        input_tensor = preprocess_image(pil_image)\n",
        "\n",
        "        # VQGAN ì¬êµ¬ì„± (í’ˆì§ˆ í™•ì¸ìš©)\n",
        "        with torch.no_grad():\n",
        "            tokens = encode_to_tokens(input_tensor, vqgan)\n",
        "            reconstructed = decode_from_tokens(tokens, vqgan)\n",
        "\n",
        "        # Inpainting\n",
        "        inpainted = inpaint_image(\n",
        "            original_image=input_tensor,\n",
        "            mask_region=mask_indices,\n",
        "            target_class=class_idx,\n",
        "            maskgit_model=maskgit,\n",
        "            vqgan_model=vqgan,\n",
        "            num_steps=int(num_steps),\n",
        "            temperature=temperature,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        # ê²°ê³¼ ë³€í™˜\n",
        "        original_pil = tensor_to_pil(input_tensor)\n",
        "        reconstructed_pil = tensor_to_pil(reconstructed)\n",
        "        inpainted_pil = tensor_to_pil(inpainted)\n",
        "\n",
        "        # ë§ˆìŠ¤í¬ ì‹œê°í™”\n",
        "        mask_preview = visualize_mask_on_image(original_pil, mask_indices)\n",
        "\n",
        "        status = f\"âœ… ì™„ë£Œ! ê²°í•¨: {CLASS_NAMES[class_idx]}, ë§ˆìŠ¤í¬: {len(mask_indices)}ê°œ í† í°\"\n",
        "\n",
        "        return mask_preview, reconstructed_pil, inpainted_pil, status\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, None, None, f\"âŒ ì—ëŸ¬: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gradio_interface",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfb3a17-a5d9-4e83-dd73-1fce9d4b751d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2325637056.py:20: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=css, title=\"ê¸ˆì† ê²°í•¨ í•©ì„±ê¸°\") as demo:\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì‹¤í–‰\n",
        "# =============================================================================\n",
        "\n",
        "# ë§ˆìŠ¤í¬ í”„ë¦¬ì…‹ ëª©ë¡\n",
        "MASK_PRESETS = [\n",
        "    \"ì¤‘ì•™ (ì‘ìŒ) 6x6\",\n",
        "    \"ì¤‘ì•™ (í¼) 8x8\",\n",
        "    \"ì¢Œìƒë‹¨ 6x6\",\n",
        "    \"ìš°í•˜ë‹¨ 6x6\"\n",
        "]\n",
        "\n",
        "# CSS ìŠ¤íƒ€ì¼\n",
        "css = \"\"\"\n",
        ".gradio-container { font-family: 'Noto Sans KR', sans-serif; }\n",
        "h1 { text-align: center; }\n",
        "\"\"\"\n",
        "\n",
        "# Gradio Blocks ì¸í„°í˜ì´ìŠ¤\n",
        "with gr.Blocks(css=css, title=\"ê¸ˆì† ê²°í•¨ í•©ì„±ê¸°\") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "# ğŸ”§ ê¸ˆì† ê²°í•¨ í•©ì„±ê¸° (Metal Defect Synthesizer)\n",
        "\n",
        "**NEU-DET / X-SDD / SD-saliency-900** ë°ì´í„°ì…‹ ê¸°ë°˜ ê¸ˆì† í‘œë©´ ê²°í•¨ Inpainting ë„êµ¬\n",
        "\n",
        "ê¸°ì¡´ ì´ë¯¸ì§€ì˜ íŠ¹ì • ì˜ì—­ì— ì›í•˜ëŠ” ê²°í•¨ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "\"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            # ì…ë ¥\n",
        "            input_image = gr.Image(\n",
        "                label=\"ì›ë³¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ\",\n",
        "                type=\"pil\",\n",
        "            )\n",
        "\n",
        "            defect_dropdown = gr.Dropdown(\n",
        "                choices=CLASS_NAMES_KR,\n",
        "                value=CLASS_NAMES_KR[5],  # scratches\n",
        "                label=\"ì¶”ê°€í•  ê²°í•¨ íƒ€ì…\",\n",
        "            )\n",
        "\n",
        "            mask_dropdown = gr.Dropdown(\n",
        "                choices=MASK_PRESETS,\n",
        "                value=MASK_PRESETS[0],\n",
        "                label=\"ë§ˆìŠ¤í¬ ì˜ì—­\",\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                steps_slider = gr.Slider(\n",
        "                    minimum=4, maximum=16, value=8, step=1,\n",
        "                    label=\"ë””ì½”ë”© ìŠ¤í…\",\n",
        "                )\n",
        "                temp_slider = gr.Slider(\n",
        "                    minimum=0.5, maximum=2.0, value=1.0, step=0.1,\n",
        "                    label=\"Temperature\",\n",
        "                )\n",
        "\n",
        "            inpaint_btn = gr.Button(\"ğŸš€ Inpainting ì‹¤í–‰\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            # ì¶œë ¥\n",
        "            status_text = gr.Textbox(label=\"ìƒíƒœ\", interactive=False)\n",
        "\n",
        "            with gr.Row():\n",
        "                mask_preview = gr.Image(label=\"ë§ˆìŠ¤í¬ ë¯¸ë¦¬ë³´ê¸°\")\n",
        "                reconstructed_output = gr.Image(label=\"VQGAN ì¬êµ¬ì„±\")\n",
        "                inpainted_output = gr.Image(label=\"Inpainting ê²°ê³¼\")\n",
        "\n",
        "    # ë²„íŠ¼ ì´ë²¤íŠ¸\n",
        "    inpaint_btn.click(\n",
        "        fn=gradio_inpaint,\n",
        "        inputs=[input_image, defect_dropdown, mask_dropdown, steps_slider, temp_slider],\n",
        "        outputs=[mask_preview, reconstructed_output, inpainted_output, status_text],\n",
        "    )\n",
        "\n",
        "    # í•˜ë‹¨ ì •ë³´\n",
        "    gr.Markdown(\"\"\"\n",
        "---\n",
        "### ğŸ“Š ì§€ì› ê²°í•¨ íƒ€ì…\n",
        "\n",
        "| ê²°í•¨ | ì‹œê°ì  íŠ¹ì§• |\n",
        "|------|------------|\n",
        "| ê°œì¬ë¬¼ | í‘œë©´ì— ë°•íŒ ì–´ë‘ìš´ ì ì´ë‚˜ ë©ì–´ë¦¬. ê¸ˆì† ë‚´ë¶€ ë¶ˆìˆœë¬¼ì´ ë“œëŸ¬ë‚œ ê²ƒ |\n",
        "| í”¼íŠ¸í™€ | í‘œë©´ì— ì›€í‘¹ íŒŒì¸ ì‘ì€ êµ¬ë©ë“¤. í€ì¹­ ì‹¤ìˆ˜ë‚˜ ì••ì—° ì¤‘ ìƒê¸´ í•¨ëª° |\n",
        "| ìŠ¤í¬ë˜ì¹˜/ì£¼ë¦„ | ê¸¸ê²Œ ê¸íŒ ì„  ìêµ­ì´ë‚˜ ì ‘í˜€ì„œ ìƒê¸´ ì£¼ë¦„ |\n",
        "| ì–¼ë£© | ë¬¼, ê¸°ë¦„ ë“±ì´ ë§ˆë¥´ë©´ì„œ ìƒê¸´ ë¶ˆê·œì¹™í•œ ë°ê±°ë‚˜ ì–´ë‘ìš´ ì˜ì—­ |\n",
        "| ê· ì—´ | ê±°ë¯¸ì¤„ì²˜ëŸ¼ í¼ì§„ ë¯¸ì„¸ ê· ì—´ì´ë‚˜ ìš©ì ‘/ì ˆë‹¨ ë¶€ìœ„ì˜ í‹ˆ |\n",
        "| ì ‘í˜/ìŠ¤ì¼€ì¼ | ì••ì—° ì¤‘ ì‚°í™”ë§‰ì´ ëˆŒë ¤ ë“¤ì–´ê°„ ì–´ë‘ìš´ ì¤„ë¬´ëŠ¬ë‚˜ ì ‘íŒ ìêµ­ |\n",
        "\n",
        "### ğŸ’¡ Tips\n",
        "- **Temperature**: ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì , ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘í•¨\n",
        "- **ìŠ¤í… ìˆ˜**: ë§ì„ìˆ˜ë¡ í’ˆì§ˆâ†‘, ì†ë„â†“\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "launch_header"
      },
      "source": [
        "## 8. ğŸš€ ì•± ì‹¤í–‰!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "outputId": "a795dbbd-5e95-4abf-bb1b-58765517cf5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://cbe2331d7e6f2a819b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cbe2331d7e6f2a819b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://cbe2331d7e6f2a819b.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ğŸš€ Gradio ì•± ì‹¤í–‰\n",
        "# =============================================================================\n",
        "\n",
        "# share=True: ê³µê°œ URL ìƒì„± (72ì‹œê°„ ìœ íš¨)\n",
        "# debug=True: ì—ëŸ¬ ìƒì„¸ ì¶œë ¥\n",
        "\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}